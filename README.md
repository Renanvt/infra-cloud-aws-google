<!--
 alobexpress-setup (c) by Jonatan Renan
 
 alobexpress-setup is licensed under a
 Creative Commons Attribution 4.0 International License.
-->

<p align="center">
  <a href="" rel="noopener">
 <img width=200px height=200px src="https://i.imgur.com/FxL5qM0.jpg" alt="Bot logo"></a>
</p>

<h2 align="center">INFRAESTRUTURA ALOB EXPRESS (MULTI-CLOUD) v2.0.1</h2>
<h3 align="center">AWS & Google Cloud | Docker Swarm | N8N | Traefik | Portainer | Evolution API | Dify AI</h3>

<div align="center">

[![Status](https://img.shields.io/badge/status-active-success.svg)]()
[![Platform](https://img.shields.io/badge/cloud-AWS%20%7C%20GCP-orange.svg)]()
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](/LICENSE)

</div>

---

<p align="center"> ü§ñ Infraestrutura como C√≥digo (IaC) moderna e unificada para automa√ß√£o de alta performance. ü§ñ
    <br> 
</p>

# üìã √çndice

- [Vis√£o Geral e Arquitetura](#-vis√£o-geral-e-arquitetura)
- [Prepara√ß√£o da Nuvem (Passo a Passo)](#-prepara√ß√£o-da-nuvem)
  - [Op√ß√£o A: Amazon AWS](#op√ß√£o-a-amazon-aws)
  - [Op√ß√£o B: Google Cloud Platform (GCP)](#op√ß√£o-b-google-cloud-platform-gcp)
- [Instala√ß√£o Automatizada](#-instala√ß√£o-automatizada)
- [P√≥s-Instala√ß√£o e Configura√ß√£o](#-p√≥s-instala√ß√£o-e-configura√ß√£o)
  - [Localiza√ß√£o dos Arquivos de Configura√ß√£o](#-localiza√ß√£o-dos-arquivos-de-configura√ß√£o)
  - [DNS (Cloudflare)](#dns-cloudflare)
  - [Banco de Dados N8N](#criar-banco-de-dados-n8n-obrigat√≥rio)
  - [CORS (Evolution API)](#-configurar-cors-para-evolution-api)
- [Custos e Otimiza√ß√£o Financeira](#-custos-e-otimiza√ß√£o)
- [Seguran√ßa e Backups Autom√°ticos](#-seguran√ßa-e-manuten√ß√£o)
- [Otimiza√ß√£o Autom√°tica de Recursos (80/20)](#-otimiza√ß√£o-autom√°tica-de-recursos)
- [üìò Guia Pr√°tico de DevOps (Docker & Cloud)](#-guia-pr√°tico-de-devops-docker--cloud)
  - [Comandos Essenciais](#comandos-essenciais)
  - [Transfer√™ncia de Arquivos](#transfer√™ncia-de-arquivos-uploaddownload)
  - [Logs e Monitoramento Avan√ßado](#logs-e-monitoramento-avan√ßado)
- [Instala√ß√£o Standalone do Dify (H√≠brido)](#-instala√ß√£o-standalone-do-dify-h√≠brido)
- [Troubleshooting](#-troubleshooting)

---

# üèó Vis√£o Geral e Arquitetura

Este projeto utiliza **Docker Swarm** para orquestrar cont√™ineres de forma resiliente e escal√°vel, suportando tanto **AWS** quanto **Google Cloud**.

### Diagrama de Infraestrutura

```mermaid
graph TD
    User((Internet User)) -->|HTTPS/443| CloudFW[Cloud Firewall]
    CloudFW -->|TCP| Traefik
    
    subgraph "Single High-Spec VM (16GB RAM)"
        Traefik[Traefik Proxy v3]
        Portainer[Portainer CE]
        
        subgraph "Data Layer"
            Postgres[(Postgres 16)]
            Redis[(Redis 7)]
            PgVector[(PgVector)]
        end
        
        subgraph "Business Apps"
            n8n[n8n Automation]
            EvoAPI[Evolution API]
            Chatwoot[Chatwoot]
            Typebot[Typebot]
        end
        
        subgraph "AI Services"
            DifyAPI[Dify API]
            DifyWeb[Dify Web]
            DifyWorker[Dify Worker]
            DifySand[Dify Sandbox]
        end
    end

    %% Routing
    Traefik --> n8n
    Traefik --> EvoAPI
    Traefik --> Chatwoot
    Traefik --> Typebot
    Traefik --> DifyWeb
    Traefik --> DifyAPI

    %% Connections
    n8n -.-> Postgres
    EvoAPI -.-> Postgres
    EvoAPI -.-> Redis
    Chatwoot -.-> Postgres
    Chatwoot -.-> Redis
    
    DifyAPI -.-> PgVector
    DifyAPI -.-> Redis
    DifyWorker -.-> PgVector
    
    style Traefik fill:#f9f,stroke:#333,stroke-width:2px
    style Postgres fill:#bbf,stroke:#333,stroke-width:2px
    style PgVector fill:#bbf,stroke:#333,stroke-width:2px
```

---

# ‚òÅ Prepara√ß√£o da Nuvem

Escolha seu provedor de nuvem e siga os passos detalhados de prepara√ß√£o.

## Op√ß√£o A: Amazon AWS

### 1. Criar Bucket S3 (Para Backups e Evolution API)
1. Acesse: [S3 Console](https://s3.console.aws.amazon.com/s3/)
2. **Create bucket** (Crie DOIS buckets separados):
   
   #### A. Bucket de M√≠dia (P√∫blico) - Para Evolution API
   - **Nome Sugerido**: `alobexpress-evolution-media-2025` (ou similar)
   - **Configura√ß√£o de Bloqueio P√∫blico**:
     - ‚¨ú Desmarque "Block all public access" (Bloquear todo acesso p√∫blico).
     - Confirme que voc√™ entende os riscos (√© necess√°rio para o WhatsApp baixar as m√≠dias).
   
   - **Bucket Policy (Leitura P√∫blica Obrigat√≥ria)**:
     1. V√° na aba **Permissions** > **Bucket policy** > **Edit**.
     2. Cole o JSON abaixo (troque `SEU_BUCKET_DE_MIDIA` pelo nome real):
     ```json
     {
         "Version": "2012-10-17",
         "Statement": [
             {
                 "Effect": "Allow",
                 "Principal": "*",
                 "Action": "s3:GetObject",
                 "Resource": "arn:aws:s3:::SEU_BUCKET_DE_MIDIA/*"
             }
         ]
     }
     ```

   - **CORS (Cross-origin resource sharing)**:
     1. Ainda na aba **Permissions**, role at√© o final em **CORS** > **Edit**.
     2. Cole o JSON abaixo (Permite que o navegador/WhatsApp baixe os arquivos):
     ```json
     [
         {
             "AllowedHeaders": ["*"],
             "AllowedMethods": ["GET", "HEAD"],
             "AllowedOrigins": ["*"],
             "ExposeHeaders": []
         }
     ]
     ```

   #### B. Bucket de Backup e Dify (Privado)
   - **Nome Sugerido**: `alobexpress-storage-2025` (ou similar)
   - **Configura√ß√£o de Bloqueio P√∫blico**:
     - ‚úÖ **Marque a op√ß√£o "Block all public access"** (Bloquear todo acesso p√∫blico).
     - Isso garante que seus backups e arquivos do Dify (RAG) n√£o fiquem expostos na internet.
   - **Bucket Policy (Acesso Restrito ao Root/IAM)**:
     ```json
     {
         "Version": "2012-10-17",
         "Statement": [
             {
                 "Sid": "PermissaoRestrita",
                 "Effect": "Allow",
                 "Principal": { "AWS": "arn:aws:iam::SEU_ACCOUNT_ID:root" },
                 "Action": [
                     "s3:PutObject",
                     "s3:GetObject",
                     "s3:ListBucket"
                 ],
                 "Resource": [
                     "arn:aws:s3:::SEU_BUCKET_DE_BACKUP",
                     "arn:aws:s3:::SEU_BUCKET_DE_BACKUP/*"
                 ]
             }
         ]
     }
     ```
     - Ative o Versionamento (Versioning).
     - Crie uma Lifecycle Rule para expirar arquivos antigos ap√≥s 30/90 dias.
3. **Regi√£o**: `us-east-1` (Recomendado).



### 2. Criar Usu√°rio IAM
1. Acesse IAM > Users > Create user.
2. Nome: `seu_negocio-user`.
3. Permiss√µes: `AmazonS3FullAccess`.
4. **Crie Access Keys** e SALVE-AS.

### 3. Criar Inst√¢ncia EC2
1. **Imagem (AMI)**: `Ubuntu Server 22.04 LTS`.
2. **Tipo**: `t3.large` (Recomendado para stack completa) ou `t3.small` (apenas N8N/Evolution).
3. **Storage**: 80GB gp3.
4. **Security Group**:
   - Permitir **SSH (22)** do seu IP.
   - Permitir **HTTP (80)** de 0.0.0.0/0.
   - Permitir **HTTPS (443)** de 0.0.0.0/0.

## Op√ß√£o B: Google Cloud Platform (GCP) - Recomendado

### 1. Criar Compute Engine (VM)
1. **Regi√£o**: `us-central1` (Iowa) ou `us-east1`.
2. **M√°quina**: `e2-standard-4` (4 vCPU, 16GB RAM) para stack completa (com Dify).
3. **Disco de Inicializa√ß√£o**:
   - Imagem: `Debian GNU/Linux 12 (bookworm)` ou `Ubuntu 22.04 LTS`.
   - Tamanho: 80GB SSD Persistente.
4. **Firewall**:
   - ‚úÖ Permitir tr√°fego HTTP.
   - ‚úÖ Permitir tr√°fego HTTPS.

---

# üöÄ Instala√ß√£o Automatizada

O script modular `install.sh` orquestra a instala√ß√£o e detecta o ambiente para ambos os provedores.

### 1. Conectar na VM
```bash
# AWS
ssh -i "sua-chave.pem" ubuntu@seu-ip-publico

# GCP (via Console ou Terminal)
gcloud compute ssh --zone "us-central1-a" "nome-da-vm"
```

### 2. Instala√ß√£o R√°pida (Recomendada)
O comando abaixo baixa o instalador e todos os m√≥dulos necess√°rios automaticamente:

```bash
curl -sL https://raw.githubusercontent.com/Renanvt/infra-cloud-aws-google/main/install.sh | sudo bash
```

### 3. Instala√ß√£o Manual (Git)
Se preferir clonar o reposit√≥rio completo:

```bash
# 1. Clone o reposit√≥rio
git clone https://github.com/Renanvt/infra-cloud-aws-google.git infra-alob
cd infra-alob

# 2. D√™ permiss√£o de execu√ß√£o
chmod +x install.sh

# 3. Execute o instalador
sudo ./install.sh
```

### 4. Instala√ß√£o Manual (Upload)
Se preferir enviar os arquivos manualmente:

```bash
# Compacte o projeto na sua m√°quina local
tar -czvf infra.tar.gz install.sh modules/

# Envie para o servidor
scp infra.tar.gz ubuntu@SEU_IP:/home/ubuntu/

# No servidor:
tar -xzvf infra.tar.gz
chmod +x install.sh
sudo ./install.sh
```

---

# ‚öô P√≥s-Instala√ß√£o e Configura√ß√£o

## üìÇ Localiza√ß√£o dos Arquivos de Configura√ß√£o
Os arquivos de configura√ß√£o `.yaml` (Docker Compose) e `.env` s√£o gerados e salvos automaticamente no diret√≥rio do neg√≥cio:
`/opt/infra/<NOME_DO_NEGOCIO>/`

## DNS (Cloudflare)
Configure seus apontamentos DNS no Cloudflare apontando para o **IP P√∫blico** da sua VM.
**Use "DNS Only" (Nuvem Cinza) inicialmente para garantir a gera√ß√£o dos certificados SSL.**

| Tipo | Nome | Destino | Coment√°rio |
|------|------|----------|------------|
| **A** | `automations` | `SEU_IP_VM` | Apontamento Principal |
| **CNAME** | `painel` | `automations.meu-dominio.com` | Portainer |
| **CNAME** | `n8n` | `automations.meu-dominio.com` | N8N Editor |
| **CNAME** | `evolution` | `automations.meu-dominio.com` | Evolution API |
| **CNAME** | `dify` | `automations.meu-dominio.com` | Dify Web |
| **CNAME** | `api` | `automations.meu-dominio.com` | Dify API |

## Criar Banco de Dados N8N (Obrigat√≥rio)
O N8N precisa que o banco de dados seja criado manualmente no primeiro uso (se o script n√£o conseguir).

1. Acesse o **Portainer** (`https://painel.seu-dominio.com`).
2. V√° em **Containers** > Encontre o `postgres`.
3. Clique no √≠cone **>_ Console** > **Connect**.
4. Execute: `psql -U postgres -c "CREATE DATABASE n8n;"`

## üõ°Ô∏è Configurar CORS (para Evolution API)
*J√° coberto na se√ß√£o [Prepara√ß√£o da Nuvem](#1-criar-bucket-s3-para-backups-e-evolution-api).*
Certifique-se de que o **Bucket de M√≠dia** possui a configura√ß√£o de CORS permitindo `GET` e `HEAD` para funcionar corretamente com o WhatsApp e Navegadores.


# üõ† Opera√ß√µes Avan√ßadas (AWS)

## Como Expandir Volume AWS

1. No Console AWS > Volumes > Modify Volume > Aumente o tamanho.
2. Na VM:
   ```bash
   # Listar discos
   lsblk
   
   # Expandir parti√ß√£o
   sudo growpart /dev/nvme0n1 1
   
   # Redimensionar sistema de arquivos
   sudo resize2fs /dev/nvme0n1p1
   ```

## Como Atachar Volume EBS
Se voc√™ precisar de um segundo disco (`/data`):

1. Crie o volume na mesma Zona de Disponibilidade (AZ).
2. Attach volume √† inst√¢ncia.
3. Na VM:
   ```bash
   # Formatar (apenas se for novo!)
   sudo mkfs -t ext4 /dev/xvdf

   # Montar
   sudo mkdir /data
   sudo mount /dev/xvdf /data
   
   # Persistir no fstab (Cuidado!)
   # UUID=... /data ext4 defaults,nofail 0 2
   ```


---

# üí∞ Custos e Otimiza√ß√£o

## AWS (Free Tier & Proje√ß√µes)
*   **EC2 (t3.small)**: ~$15-20/m√™s (B√°sico).
*   **EC2 (t3.large)**: ~$60-70/m√™s (Stack Completa).
*   **EBS (80GB)**: ~$8/m√™s.

### Breakdown de Custos Mensais AWS
![Breakdown 1](img/1.PNG)
![Breakdown 2](img/2.PNG)

### Proje√ß√£o de Custos Real
![Proje√ß√£o](img/3.PNG)

## Google Cloud (Estimativas)
*   **VM Principal (e2-standard-4)**: ~$105,84/m√™s (Alta performance, 16GB RAM).
*   **VM M√©dia (e2-standard-2)**: ~$57,42/m√™s (8GB RAM).

### Otimiza√ß√µes
1.  **S3 Lifecycle (Automa√ß√£o de Custos)**:
    Para reduzir custos, configure o S3 para mover backups antigos para "Glacier" (armazenamento frio/barato) e apagar ap√≥s 90 dias.
    
    1. Crie um arquivo chamado `s3-lifecycle.json` com o conte√∫do abaixo:
    ```json
    {
        "Rules": [
            {
                "ID": "MoveToGlacierAndExpire",
                "Prefix": "backups/",
                "Status": "Enabled",
                "Transitions": [
                    {
                        "Days": 30,
                        "StorageClass": "GLACIER"
                    }
                ],
                "Expiration": {
                    "Days": 90
                }
            }
        ]
    }
    ```
    
    2. Aplique a regra no seu bucket de backup:
    ```bash
    aws s3api put-bucket-lifecycle-configuration --bucket NOME_DO_BUCKET_BACKUP --lifecycle-configuration file://s3-lifecycle.json
    ```

2.  **N8N Pruning**: O script j√° configura limpeza autom√°tica de execu√ß√µes antigas (72h) para economizar disco.

## Sistema de Backups Autom√°ticos (S3)

O sistema inclui scripts para realizar backups completos (Banco de Dados + Volumes) e envi√°-los para um Bucket S3 da AWS.

### 1. Requisitos no S3
1. Crie um Bucket S3 (ex: `alobexpress-storage-2025`).
2. **Importante**: Crie uma pasta chamada `backups/` (no plural) dentro deste bucket. O script espera encontrar esta pasta.

### 2. Permiss√µes AWS
Certifique-se de que as permiss√µes foram configuradas conforme a [Se√ß√£o de Prepara√ß√£o](#1-criar-bucket-s3-para-backups-e-evolution-api).

Se voc√™ optou por criar um **Usu√°rio IAM Dedicado** (em vez de usar a Bucket Policy no root), adicione esta pol√≠tica ao usu√°rio:
```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "PermissaoBackupS3",
            "Effect": "Allow",
            "Action": [
                "s3:PutObject",
                "s3:ListBucket"
            ],
            "Resource": [
                "arn:aws:s3:::alobexpress-storage-2025",
                "arn:aws:s3:::alobexpress-storage-2025/backups/*"
            ]
        }
    ]
}
```

### 3. O que √© salvo?
O script `backup_to_s3.sh` realiza o backup de todos os componentes cr√≠ticos:
*   **N8N**: Todos os fluxos, credenciais e hist√≥rico (via Dump do Postgres).
*   **Dify**: Base de conhecimento (Vector Store), fluxos e configura√ß√µes (via Dump do Postgres + PgVector).
*   **Evolution API**: Inst√¢ncias e sess√µes (via Volume `evolution_v2_data`).
*   **Infra**: Certificados SSL (Traefik) e dados do Portainer.

**Nota sobre o Arquivo de Backup (.tar.gz):**
O arquivo gerado no S3 possui a extens√£o `.tar.gz`. Se voc√™ baixar e extrair este arquivo no Windows, ele pode aparecer como uma pasta com o mesmo nome do arquivo (ex: `backup_20251231_144856`). Dentro desta pasta, voc√™ encontrar√° os arquivos SQL e pastas de volume. Isso √© normal e esperado.

### 4. Executando o Backup

#### Op√ß√£o A: Backup para S3 (Recomendado)
**Execu√ß√£o Manual:**
```bash
# Execute e siga as instru√ß√µes interativas
./backup_to_s3.sh
```

**Instala√ß√£o R√°pida (Curl):**
Se o arquivo n√£o existir (nova VM), baixe e execute diretamente:
```bash
curl -sL "https://setup.alobexpress.com.br/backup_to_s3.sh" -o backup_to_s3.sh
chmod +x backup_to_s3.sh
sudo ./backup_to_s3.sh
```

**Automa√ß√£o (Cron):**
Para rodar todo dia √†s 03:00am, adicione ao crontab (`crontab -e`):
```bash
0 3 * * * S3_BUCKET=alobexpress-storage-2025 S3_REGION=us-east-1 S3_ACCESS_KEY=SUA_KEY S3_SECRET_KEY=SUA_SECRET /opt/infra/NOME_DO_NEGOCIO/backup_to_s3.sh >> /var/log/backup_s3.log 2>&1
```

#### Op√ß√£o B: Backup Local (VM)
Ideal para snapshots r√°pidos antes de mudan√ßas. O script salva localmente e gerencia rota√ß√£o (padr√£o: 7 dias).

**Instala√ß√£o R√°pida (Curl):**
```bash
curl -sL "https://setup.alobexpress.com.br/backup_to_vm.sh" -o backup_to_vm.sh
chmod +x backup_to_vm.sh
sudo ./backup_to_vm.sh
```

**Vari√°veis Opcionais:**
Voc√™ pode definir o diret√≥rio e reten√ß√£o:
```bash
BACKUP_ROOT_DIR=/meus/backups RETENTION_DAYS=15 ./backup_to_vm.sh
```

### 5. Restaurando Backup (Disaster Recovery)

Se voc√™ precisar restaurar um backup (ex: migra√ß√£o de servidor ou recupera√ß√£o de desastre), use o script `restore_from_s3.sh`.

1. **Baixe e execute o script**:
   ```bash
   # Se o reposit√≥rio j√° estiver clonado:
   sudo ./restore_from_s3.sh
   
   # Ou baixe e execute diretamente (em nova VM):
   curl -fsSL https://raw.githubusercontent.com/alob-express/infra-alob-express/main/restore_from_s3.sh -o restore_from_s3.sh
   chmod +x restore_from_s3.sh
   sudo ./restore_from_s3.sh
   ```

2. **Siga o assistente**:
   - O script pedir√° suas credenciais S3.
   - Listar√° os backups dispon√≠veis.
   - Baixar√° e restaurar√° automaticamente Volumes e Banco de Dados.

> **Nota**: O script gerencia a parada/in√≠cio da stack se necess√°rio para garantir a integridade dos dados.

# ‚ö° Otimiza√ß√£o Autom√°tica de Recursos

O sistema aplica a regra de ouro de **80/20** para evitar travamentos e garantir estabilidade sob alta carga:

*   **Limite M√°ximo (Limits)**: Containers podem usar at√© 80% da RAM total dispon√≠vel.
*   **Reserva Garantida (Requests)**: 10% reservado para servi√ßos cr√≠ticos (Garantia de QoS).

**Dify AI (SLA)**: Para o Dify, garantimos 2 vCPUs e 4GB de RAM dedicados para evitar queda de conex√µes durante processamento de vetores.

### Monitoramento em Tempo Real (DevOps)
Para verificar se a aloca√ß√£o de recursos est√° adequada:

```bash
# Ver consumo de CPU/RAM em tempo real
docker stats --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.MemPerc}}"

# Verificar limites definidos
docker inspect NOME_CONTAINER --format '{{.HostConfig.Memory}}'
```

---



# üìò Guia Pr√°tico de DevOps (Docker & Cloud)

Esta se√ß√£o cont√©m comandos e procedimentos essenciais para o dia a dia.

## Comandos Essenciais

### Gest√£o de Stacks (Servi√ßos)
```bash
# Listar servi√ßos rodando
docker service ls

# Ver logs de um servi√ßo (tempo real)
docker service logs -f NOME_SERVICO

# Reiniciar um servi√ßo (for√ßar update)
docker service update --force NOME_SERVICO
```

### Gest√£o de Containers Individuais
```bash
# Listar todos (inclusive parados)
docker ps -a

# Ver logs de um container espec√≠fico
docker logs --tail 100 -f NOME_CONTAINER

# Entrar no terminal do container
docker exec -it NOME_CONTAINER /bin/sh
```

### Manuten√ß√£o Completa (Parar/Iniciar)

**Parar tudo com seguran√ßa:**
```bash
docker stack rm traefik portainer postgres redis rabbitmq n8n_editor n8n_worker n8n_webhook evolution_v2 dify_pgvector dify_sandbox dify_api dify_web dify_worker
```

**Iniciar tudo:**
```bash
# 1. Infra
docker stack deploy -c infra/04.traefik.yaml traefik
docker stack deploy -c infra/05.portainer.yaml portainer
docker stack deploy -c infra/06.postgres.yaml postgres
docker stack deploy -c infra/07.redis.yaml redis
docker stack deploy -c infra/11.rabbitmq.yaml rabbitmq

# 2. Apps
docker stack deploy -c infra/08.n8n-editor.yaml n8n_editor
docker stack deploy -c infra/18.evolution_v2.yaml evolution_v2
# ... (demais servi√ßos)
```

## Transfer√™ncia de Arquivos (Upload/Download)

### Baixar da VM para seu PC
**M√©todo via Navegador (SSH GCP):**
1. Na VM: `sudo tar -czf /tmp/backup.tar.gz /caminho/da/pasta`
2. No SSH do Navegador: Clique na engrenagem ‚öôÔ∏è > **Download file** > Digite `/tmp/backup.tar.gz`.

**M√©todo via Terminal (gcloud):**
```bash
gcloud compute scp INSTANCIA:/tmp/backup.tar.gz ~/Downloads/ --zone=us-central1-a
```

### Enviar do PC para a VM
```bash
gcloud compute scp ~/Downloads/arquivo.txt INSTANCIA:/tmp/ --zone=us-central1-a
```


## üîÑ Guia de Restaura√ß√£o de Backup (S3)

Se voc√™ precisa restaurar dados de um backup anterior, siga este checklist rigoroso para garantir a integridade dos dados.

### ‚úÖ Checklist Pr√©-Restaura√ß√£o

**1. Pr√©-requisitos de Acesso:**
Certifique-se de que voc√™ consegue acessar as URLs dos servi√ßos (mesmo que vazios):
- [ ] Portainer: `https://${PORTAINER_DOMAIN}`
- [ ] N8N Editor: `https://${N8N_EDITOR_DOMAIN}`
- [ ] RabbitMQ: `https://${RABBITMQ_DOMAIN}`
- [ ] Evolution API: `https://${EVOLUTION_DOMAIN}`
- [ ] Dify (se instalado): `https://${DIFY_WEB_DOMAIN}`

**2. Tempo de Estabiliza√ß√£o:**
- [ ] Aguarde pelo menos **5 minutos** ap√≥s o in√≠cio dos containers.
  - *Motivo:* O Postgres precisa inicializar o banco e rodar migrations iniciais antes de aceitar sobrescrita de dados.

**3. Status dos Servi√ßos:**
- [ ] Verifique no Portainer se todos os containers est√£o com status `running` ou `healthy`.
- [ ] N√£o inicie a restaura√ß√£o se houver containers em `restarting`.

### üöÄ Executando a Restaura√ß√£o

**Op√ß√£o A: Durante o Setup**
O script de instala√ß√£o perguntar√° ao final se deseja restaurar. Responda `sim` e siga o assistente.

**Op√ß√£o B: Manualmente (P√≥s-instala√ß√£o)**
```bash
cd /opt/infra/NOME_DO_NEGOCIO
sudo ./restore_from_s3.sh
```

### ‚è≥ P√≥s-Restaura√ß√£o

1. O script pode solicitar a reinicializa√ß√£o da stack.
2. Ap√≥s o t√©rmino, **aguarde novamente 2 a 5 minutos** para que os servi√ßos carreguem os dados restaurados do disco para a mem√≥ria.
3. Valide se seus fluxos (N8N), inst√¢ncias (Evolution) e dados (Dify) reapareceram.

---

## Logs e Monitoramento Avan√ßado

### Ver logs de TODOS os containers rodando (Script R√°pido)
```bash
for container in $(docker ps --format '{{.Names}}'); do 
    echo "=== Logs de $container ===" 
    docker logs --tail 50 $container 
    echo "" 
done
```

### üßπ Limpeza Segura de Disco (Best Practices)

Evite usar `docker system prune -a --volumes` cegamente, pois isso apaga dados persistentes! Use os comandos abaixo:

#### 1. Diagn√≥stico
```bash
# Ver quanto espa√ßo voc√™ vai liberar (SEM apagar nada)
docker system df

# Ver espa√ßo em disco do sistema
df -h
```

#### 2. Limpeza Segura (Sem perda de dados)
```bash
# Limpar apenas containers parados
docker container prune

# Limpar apenas imagens "dangling" (imagens quebradas/sem tag)
docker image prune

# Limpar redes n√£o usadas
docker network prune

# Limpar todas imagens n√£o usadas (MANT√âM volumes/dados)
docker system prune -a
```

#### 3. Gest√£o de Volumes (Cuidado!)
```bash
# Listar todos os volumes
docker volume ls

# Ver onde o volume est√° sendo usado
docker ps -a --filter volume=NOME_DO_VOLUME

# Backup de volume (Exemplo)
docker run --rm -v NOME_VOLUME:/data -v $(pwd):/backup alpine tar czf /backup/volume-backup.tar.gz /data
```

> **Recomenda√ß√£o**: Use `docker system prune -a` para limpeza geral. Isso limpa containers parados, imagens n√£o usadas e redes, mas **MANT√âM seus volumes e bancos de dados intactos**.

---

# ü§ñ Instala√ß√£o Standalone do Dify (H√≠brido)

Para rodar o Dify em uma VM separada (H√≠brido: AWS <-> GCP), use o script dedicado:

```bash
curl -sL https://setup.alobexpress.com.br/setup_dify.sh | sudo bash
```

Siga o assistente interativo para configurar a integra√ß√£o de rede entre as duas VMs.

---

# üö® Troubleshooting

### Container reiniciando (Loop)
1. Verifique os logs: `docker logs --tail 50 NOME_CONTAINER`
2. Geralmente √© falta de mem√≥ria (OOM Kill) ou erro de conex√£o com banco.
3. Se for mem√≥ria, ajuste os limites no arquivo YAML correspondente em `vm/`.

### "Port is missing" no Traefik
Certifique-se de que o servi√ßo tem a porta definida nos labels ou no `loadbalancer.server.port`.

### Erro S3 "ENOTFOUND"
Verifique se o endpoint do S3 est√° sem `https://`. O Evolution V2 requer apenas o hostname (ex: `s3.us-east-1.amazonaws.com`).

---
<img width=200px height=200px src="img/5.PNG" alt="Bot logo"></a>

**Vers√£o**: 2.0.1 | **Atualizado**: Dezembro 2025
